## 2023秋季学期第6周总结

### 1. Clustering based Behavior Sampling with Long Sequential Data for CTR Prediction
- **推荐任务**：点击率预估
- **选自**：SIGIR2022
- **解决的问题**
  长期的用户行为历史数据中存在大量噪声，且对长行为序列的处理有较高的时空成本。
- **思路和模型**
  - 思路
    - 传统方式存在以下几个问题：
      - 仅使用最近的一段用户行为序列作为输入，导致存在于历史行为中的长期或周期性模式被忽视
      - 用某种方式将长序列压缩为短序列，存在信息丢失问题
      - 基于记忆和搜索的方法引入了大量无关行为和噪声
    - 一个可行方案：从长序列中选出与每个CTR预测目标最相关的样本
  - 模型：用户行为聚类采样（User Behavior Clustering Sampling, UBCS）
    - 分为两个级联的模块：**行为采样模块**和**项目聚类模块**
    - **行为采样模块**进行考虑相关性和时间信息的采样，从用户历史序列中获取短序列；同时为了保证训练质量，设计了一个自监督的预训练任务来提取用户偏好
    - **项目聚类模块**通过聚类减少噪声影响，提高效率
- **实验数据集**
  - 亚马逊数据集Books子集
  - 亚马逊数据集Cloth子集


### 2. Analyzing and Simulating User Utterance Reformulation in Conversational Recommender Systems
- **推荐任务**：对话推荐
- **选自**：SIGIR2022
- **解决的问题**
  针对评估对话推荐系统的用户模拟，当对话代理（conversational agent）无法理解当前对话时，模拟的用户该如何重新进行表述。
- **思路和模型**
  - 思路
      - 用户模拟在任务型对话系统中已有应用，但多用于训练基于强化学习的对话系统，而很少用于推荐系统的评估。
      - 现有的用户模拟鲁棒性有限，生成的话语不能被对话代理理解时，多是终止或重新开始对话。
      - 对不同领域的相关会话用户进行研究，了解用户在遇到对话代理不理解表述时怎样重新表述。
      - 引入重述序列生成任务（改进或简化）
  - 模型
      - 以transformer为基础模型
          - 表述重构的类型(改进或简化)作为指导因素输入
          - 构建一种评估语句阅读难度的方法，对表述晦涩的话语进行二次过滤
- **实验数据集**
  - 选择了五个现有的第三方对话代理进行测试
      - And chill：在facebook上进行互动并提供Netflix推荐的电影主题聊天机器人
      - Jarvis：一个基于柏拉图研究对话系统的电影推荐系统
      - IAI Movie Bot：一个开源的、具有多模态聊天界面的电影推荐系统
      - Eddy Travel Bot：telegram上的旅行助理
      - VKM Bot：telegram上的音乐机器人
  - 采用众包实验进行用户统计信息和对话的收集，从而构建数据集


### 3. CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems
- **推荐任务**：推荐公平性
- **选自**：SIGIR2022
- **解决的问题**
  当使用推荐系统辅助做出决策时，可能会产生不公平的现象。而以往的解决方式是将用户和项目的公平性分开考虑，过于简单。
- **思路和模型**
  - 思路
      - 常见的公平性推荐多将问题框架化为满足特定标准的构架算法，如生产者公平和消费者公平，不够细致科学。
      - 有助于权衡多方利益从而保证公平性的两个主要方面：
          - 区分利益类型：曝光公平：项目均等第曝光给各用户；有效性公平：各用户得到的项目推荐有效性。
          - 区分利益相关者：对于消费者，公平是均在用户之间均匀分配；对于生产者，他们更加关心曝光公平。
      - 当前公平推荐系统的研究存在割裂，较少关心生产者方面的公平性，同时关注消费者和生产者公平性的则更是少数。
  - 模型：一种联合优化市场目标的模型不可知重排序(model-agnostic re-ranking)方法
      - 将重排序问题形式化为一个整数规划方法
      - 提出一个有效的贪心算法，在多项式时间内实现多利益相关目标的最优权衡
- **实验数据集**
  - MovieLens
  - Epinion
  - Gowalla
  - LastFM


### 4. CORE: Simple and Effective Session-based Recommendation within Consistent Representation Space
- **推荐任务**：会话推荐
- **选自**：SIGIR2022
- **解决的问题**
  非线性编码器学习到的会话嵌入(session embedding)通常与项目嵌入不在同一表示空间，导致推荐项目的预测不一致。
- **思路和模型**
  - 思路
      - 短会话内的用户行为一般都会有一个共同的焦点，会话嵌入应反应用户的短期偏好，且与建好项目的嵌入相差不大。
      - 使用基于非线性神经网络的编码器生成的会话嵌入，不一定能落在由项目嵌入的基向量构成的空间中。即表示空间不是一致的。
      - 总结为两个主要挑战：
          - 如何利用深度非线性神经网络的表示能力，设计一个更加合适的编码器。
          - 统一表示空间后，项目嵌入将直接参与评分计算和模型优化，如何避免过拟合。
      - 解决方式：
          - 将会话嵌入编码为项目嵌入的线性组合，保证表示空间的一致
          - 从优化元祖损失的角度重新审视点击距离度量，提高了距离度量的鲁棒性      
  - 模型
      - 设计了一致表示的编码器，保证会话和项目在同一个表示空间中    
      - 提出了一种更具鲁棒性的距离度量方法，防止一致表示空间中嵌入的过拟合。        
- **实验数据集**
  五个公开数据集：
  - Diginetica
  - Nowplaying
  - RetailRocket
  - Tmall
  - Yoochoose


### 5. FUM: Fine-grained and Fast User Modeling for News Recommendation
- **推荐任务**：新闻推荐
- **选自**：SIGIR2022
- **解决的问题**
  针对新闻推荐中的用户建模，传统方法将用户点击的新闻独立编码为新闻嵌入(embedding)，再聚合为该用户的用户嵌入。该方法忽略了来自同一用户点击的不同新闻之间在词汇方面的交互，从而缺失了大量可用于推断用户兴趣的信息。
- **思路和模型**
  - 思路
      - 传统模型存咋对同一用户点击的不同新闻词汇交互信息的利用缺失
      - 从比较符合直觉的例子出发，一个用户在点击的新闻1中存在“电影”一词，而在点击新闻2中存在“铁人”一词，则可以猜测用户对电影《钢铁侠》感兴趣
      - 将用户点击的新闻拼成一篇长文档，从而将用户建模转化为新闻内和新闻间词汇级交互的文档建模
  - 模型：细粒度快速用户建模(Fine-grained and Fast User Modeling, FUM)框架
      - 使用Fastformer Transformer对多个新闻拼成的长新闻进行细粒度的行为交互建模
      - 使用传统的Vanilla Transformer进行粗粒度的用户建模
      - 对两个不同粒度的建模结果进行聚合
- **实验数据集**
  - MIND：基于微软新闻用户数据的公开数据集
  - Feeds：基于从微软新闻推送中采样得到的用户数据


### 6. Ada-Ranker: A Data Distribution Adaptive Ranking Paradigm for Sequential Recommendation
- **推荐任务**：序列推荐
- **选自**：SIGIR2022
- **解决的问题**
  对于使用深度神经网络的排序器(ranker)，经典的参数冻结(parameter-frozen)推理方法不能适应动态的服务环境，有时排序器需要根据服务环境动态地调整参数。
- **思路和模型**
  - 思路：
      - 候选物品列表是由特定用户请求决定的，而对于不同请求，候选物品列表的潜在分布可能相差很大
      - 基于深度神经网络的排序器在推理时都是冻结参数的，应对复杂多变的场景时不够灵活，产生的排序结果仅是次优的
      - 现有的解决方案多为提供针对几个常见场景的模型，依旧具有局限性，且切换模型开销较大
  - 模型：训练推理范式，Ada-Ranker。根据当前候选集的数据分布自适应地调整ranker的参数
      - 将处理每个用户请求的候选集作为一个个单独的任务
      - 通过分布学习、输入调整和参数调整三个步骤使模型适应当前排序任务
- **实验数据集**
  - ML10M数据集：电影推荐
  - 淘宝数据集：电子商务、在线交易相关的数据
  - Xbox数据集：私有数据集。游戏日志


### 7. Locality-Sensitive State-Guided Experience Replay Optimization for Sparse Rewards in Online Recommendation
- **推荐任务**：在线推荐
- **选自**：SIGIR2022
- **解决的问题**
  对于在线学习中深度强化学习(Deep reinforcement learning, DRL)代理的训练，存在候选项空间较大，和用户交互较少导致的稀疏奖励问题。
- **思路和模型**
  - 思路
      - 目前广泛研究的利用经验回放(experience replay, ER)克服稀疏奖励问题的方案对在线推荐系统的复杂环境**适应性较差**、从过去经验中学习到最有策略的**效率低**。
      - 深度Q学习需要在候选项空间上执行“最大化”(maximize)操作，而这一操作在面临高维的候选项空间时，将会难以进行。
      - 基于策略梯度的方法可以有效缓解在高维候选空间中最大化操作难以进行的问题，但更加容易收敛到次优解。
      - 结合深度Q学习和策略梯度的优点，得到一个混合模型，将会带来模型综合性能的提升。
  - 模型：状态感知经验重放模型(state-aware experience replay model)
      - 以演员-评论家(actor-critic)网络为主要框架    
      - 提出局部敏感经验重放(Locality-sensitive Experience Replay, LSER)结构，包含：
          - 一种局部敏感的哈希方法，选择性地保留最有价值的经验
          - 一种奖励驱动优先策略，以更高的机会重放更有价值的经验
            与现有的随机或均匀采样不同，只重放来自相似状态的经验
- **实验数据集**
  使用三个公共仿真平台提供的模拟用户服务完成实验：
  - Virtual TB
  - Rec Sim
  - Gym