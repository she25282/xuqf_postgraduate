陈曦

2023秋季学期第3周总结

完成事项：
1. 了解NLP+推荐系统领域相关顶会，并收集了部分会议论文。
2. 寻找推荐系统相关书籍，开始了解推荐系统。
3. 收集了包括Zotero、知云等在内的论文阅读相关工具，方便后续学习开展。

本周计划：
1. 以SIGIR和SIGKDD两个会议的论文为主，开始大致阅读近几年的论文
2. 阅读《深度学习推荐系统》(王喆著)


2023秋季学期第4周总结

完成事项：从SIGKDD入手，阅读推荐系统相关论文，以及大模型相关的论文。

----------------------------------------------
1 Rank-heterogeneous Preference Models for School Choice
----------------------------------------------
- 主要观点：认为决策者（被推荐者）的偏好可能由于选择疲劳或者偏好发生变化，从而对推荐列表中处在不同位置的选项有着不同的选择标准
- 应用场景：学校推荐列表中对学校推荐度的计算
- 主要工作：传统多项式logit模型进行了改进。具体为以下几点：
	①在学校排名设置汇总使用了context-dependent random utility model(基于上下文的离散选择模型，CDM)
	②在前文中提升过排名的内容再次出现时，考虑降低其排名
	③根据次序将选择建模分层，对相邻次序的模型使用拉普拉斯正则化。

----------------------------------------------
2 Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler
----------------------------------------------
- 主要观点：不同的弱标签数据源有着不同的标注错误率，产生了可能相互冲突的噪声。而处理若监督序列标注的方法：①基于隐马尔科夫(HMM)的图模型缺少对上下文信息的利用；②特定源扰动(source-specific perturbation)深度学习模型网络结构复杂，可解释性较差。
- 应用场景：序列标注
- 主要工作：针对现有弱监督序列标注方法存在的问题，提出了一种神经化的无向图模型Neural-Hidden-CRF


----------------------------------------------
3 Reducing Exposure to Harmful Content via Graph Rewiring
----------------------------------------------
- 主要观点：不同平台提供的媒体内容可能包含有害信息；数字平台的推荐算法可能导致过滤气泡(信息茧房)、加剧极端化。
- 应用场景：有害信息过滤
- 主要工作：引入贪心近似最小曝光(Greedy approximate minimization of exposure，GAMMINE)算法，贪心地找出让有害信息曝光度最小的网络布线

----------------------------------------------
4 The Information Pathways Hypothesis: Transformers are Dynamic Self-Ensembles
----------------------------------------------
- 主要观点：
	- transformer在多层之间，可能的连接模式数量是呈指数增长的，但对性能的贡献却十分有限
	- transformer中的较为稀疏的子网络（信息通路）可以独立训练，但它自身的特性也使得对自注意力的的修剪却较为困难
- 应用场景：transformer训练占用资源和速度的优化
- 主要工作：
	- 采用随机下采样自注意力（Stochastically Subsampled self-Attention，SSA）作为新的训练策略，降低内存和计算成本、提升泛化能力
	- 选取transformer中的关键子网络，更加充分地训练这些部分，对较为冗余的连接做裁剪

总结：
	①这周看的推荐系统相关论文都是偏数学理论方面的改进和优化，对数学要求比较高，难度较大。可能不太适合我。
	②可以得知对于现有模型细节方面的质疑和优化是个发掘创新点的好方向。
	③近期transformer相关的论文多为尝试做“减法”，包括减少数据需求量、减少训练时内存需求和优化网络连接、减少参数等。
