### 一、调研

#### 旧模型应对新数据/任务：增量学习、元学习、预训练

- **增量学习**：缓解模型在学习新知识的时候对旧知识的遗忘。通过参数隔离、修改模型或数据集等方式兼顾新旧任务。
- **元学习**：自动调整超参数，训练一个学习能力强的模型。通过训练过程中学习到能更好适应新任务的超参数。
- **预训练**：通过在**大量**数据集上的预训练过程得到一个较优的初始参数，后续可以通过微调使模型快速适应新任务。

#### 增量学习 vs 元学习

- 增量学习与元学习都可以同时兼顾新旧任务。
- 增量学习在针对新任务训练时不需要或仅需要少量旧数据参与，而新旧数据都能同时参与到元学习模型的训练中。
- 元学习常被用来解决增量学习的问题，但元学习还有能自主优化初始权重和超参数等优点。

#### 元学习 vs 预训练

- 元学习和预训练都能得到快速适应新任务的模型。
- 元学习试图学习如何学习，强调的是**学习策略**的设计和优化；预训练则利用大量无监督数据训练，强调找到**最通用的先验知识/分布**。
- 元学习得到的模型适应力更强，在经过多个不同任务的迭代后仍可在原任务中有较好表现；预训练模型针对某个任务进行微调后，如果再在此基础上次针对另外一个相关性不高的任务微调，可能会影响模型在原任务中的表现。

#### 元学习现状

- 在CV领域长期广泛运用，近年来逐渐在NLP领域中得到运用。
- 单纯使用元学习得到的模型效果可能不如一般的监督学习，多结合其他方法，如利用预训练模型作为backbone，利用元学习代替传统微调，有训练效率上的优势。

#### 推荐系统中的元学习

- 解决冷启动问题：新用户、新项目、新会话...
- 解决数据稀疏问题：用户-项目交互稀疏

## 二、论文总结

### 1.Causal Incremental Graph Convolution for Recommender System Retraining

* **推荐任务** ：协同过滤
* **选自** ：TNNLS2022
* **解决的问题** ：如何仅使用新数据对基于GCN的模型进行更新，并达到完整模型重新训练的推荐精度。
* **思路和模型** ：
  * 思路：
    * 基于GCN的推荐任务中，对模型增量学习的关注较少。
    * 合并新旧数据，将模型完整重新训练效果很好，但成本非常高，且会随着时间不断增加。
    * 通过构建具有新交互的训练示例，对旧模型进行微调的成本相较完整训练更少，但由于还需要使用旧图更新参数，成本依然很高。
    * 仅利用新的交互来训练模型和图卷积。由于增量图较为稀疏，因此对计算资源的需求很小。但这样可能会切断旧图中的某些连接，容易产生过拟合和灾难性遗忘。
    * 高效的GCN推荐器再训练需要能够分离旧图、保留现有长期偏好、以及融合新旧偏好信号。
  * 模型：因果增量图卷积方法
    * 增量图卷积算子：
      * 度同步器：学习基于度的结点归一化权重，从而接近全图卷积中的归一化权重。
      * 表示聚合器：组合旧表示和新邻居，有效编码长期和短期信号。
    * 碰撞效应蒸馏算子：将整个增量训练阶段构建为因果图，通过控制碰撞器来估计新数据对不活动节点表示的因果影响，从而避免不在增量图中的非互动结点的过时问题。
* **实验数据集** ：
  * Yelp
  * Gowalla
  * Adressa

### 2. CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning

* **推荐任务** ：顺序推荐
* **选自** ：CIKM2023
* **解决的问题** ：传统SR方法利用信息传播和演化从批量交互中挖掘信息，忽略了其他用户的影响，且在所有历史交互中使用信息演化会淡化最新交互的重要性。
* **思路和模型** ：
  * 思路：
    * 除了交互本身，交互的时间戳也能提供时间动态方面的信息。
    * 现有方法无法捕捉随时间变化的兴趣动态，忽略了最近的上下文对用户动态兴趣的影响。
  * 模型：上下文感知伪多任务推荐(Context-aware Pseudo-Multi-Task Recommender)
    * 分别在静态嵌入、历史时间状态和上下文时间状态下位每个用户/项目创建三种表示
    * 伪多任务学习范式：由1个真实塔和2个伪塔组成，将增量单目标推荐堆叠到一个多目标任务中联合优化，提高时间状态演化和增量推荐的性能。
    * 1个真实塔(real tower)：进行增量预测。
    * 2个伪塔(pseudo tower)：根据新交互更新各自的时间状态，提供给下一次循环。
    * 采用共享底层(shared-bottom)网络来进行跨历史和上下文的时间状态演化，并在用户层面将两者融合。
* **实验数据集** ：
  * Patio，Lawn and Garden：Amazon review子集
  * Amazon Instant Video：Amazon review子集
  * Video Games：Amazon review子集
  * ML-100K

### 3. Deployable and Continuable Meta-learning-Based Recommender System with Fast User-Incremental Updates

* **推荐任务** ：增量推荐
* **选自** ：SIGIR2022
* **解决的问题** ：现有基于元学习的解决用户冷启动问题的方法尚不成熟，无法实际应用
* **思路和模型** ：
  * 思路：
    * 现有基于元学习的RS是在离线环境下设计的，不会利用部署后遇到的新用户数据持续优化元模型。
    * 大多数基于元学习的RS通过支持集和查询集估计二阶导数，导致更新时的计算负担很重。
    * 要实现可部署的元学习RS，需要满足：
      * 1)避免灾难性遗忘
      * 2)稳定快速地进行用户增量更新
      * 3)有限的内存消耗
      * 4)易于实现、易于计算。
    * 广泛使用的增量RS方法有三种：完全再训练(FR)、基于样本的再训练(SR)和微调(FT)
    * FR违反了要求2、3，FT不满足要求1，SR是两者的折中，但也不能很好地整合两者的优点。
  * 模型：可部署且可持续的元学习推荐(Deployable and Continuable Meta-learning-Based Recommender, DCMR)
    * 通过最小化蒸馏损失，本地更新重放任务的自适应模型。
    * 面向RS反馈的蒸馏损失：在重放任务中复制存储在元模型中的隐式知识。
    * 通过任务重传播和一阶梯度下降实现快速的用户增量更新。
    * 在本地更新中，仅更新新任务的任务表示参数，避免重放任务的干扰。
* **实验数据集** ：
  * MovieLens-1M
  * MovieLens-20M
  * Bookcrossing

### 4. Graph Few-shot Class-incremental Learning

* **推荐任务** ：增量学习
* **选自** ：WSDM2022
* **解决的问题** ：图少样本增量问题
* **思路和模型** ：
  * 思路：
    * 现有的结点分类工作主要集中在单个任务上，而实际情况中图不断增长，会有新的节点类别出现。
    * 新出现的节点类别只有很少的标记样本可用，存在严重的类不平衡问题。
    * 这样的图少样本类增量学习(Graph Few-shot Class-incremental Learning, Graph FCL)问题较少受到关注。
    * 图FCL的主要挑战是如何权衡现有任务上的性能，和获取新知识的能力。
    * 现有方法要么固定原模型特征编码器，难以学习增量任务；要么训练后在原有任务上表现不佳。
  * 模型：分层注意力图元学习框架(Hierarchical Attention Graph Meta learning, HAG-Meta)
    * 图伪增量学习范式：
      * 在基类上预训练编码器，并在后续增量学习中不冻结编码器。
      * 通过从基类和伪新类中循环采样任务，为模型产生任意数量的训练集练习增量学习技能。
    * 任务敏感正则化器：使用动态缩放的交叉熵，根据任务级注意力和结点类原型进行计算，减轻对新类或基类的过拟合。
    * 层次注意力模块：捕获不同人物的重要性并学习缩放因子。
      * 任务级注意力：根据每个任务的聚合原型估计其重要性，输出缩放因子以平衡不同任务的贡献。
      * 节点级注意力：学习能在节点内现有知识和新知识之间保持平衡的模型，提供给任务级注意力。
* **实验数据集** ：
  * Amazon-Clothing
  * DBLP
  * Reddit

### 5. Graph Structure Aware Contrastive Knowledge Distillation for Incremental Learning in Recommender Systems

* **推荐任务** ：增量推荐
* **选自** ：CIKM2021
* **解决的问题** ：随着信息量的增长和训练GNN所需的高计算复杂度，难以频繁更新模型以提供更好的推荐。
* **思路和模型** ：
  * 思路：
    * 基于GNN的推荐系统训练耗时，而仅选择部分较新的数据训练会产生灾难性遗忘问题。
    * 知识蒸馏/正则化是增量学习中常采用的方法，而现有利用知识蒸馏的工作也继承了知识蒸馏的缺点，难以捕获高阶依赖关系。
    * 保留中间层的表示通常具有更宽泛的接受域(涵盖更多跳的邻居信息)，能更好地保留模型属性，但很少在现有工作中被使用。
  * 模型：图结构感知对比知识蒸馏
    * 针对基于图的推荐模型定制对比学习目标。
    * 着重关注推荐上下文中的关系信息。
    * 结合对比蒸馏和中间层蒸馏，从而注入层级监督，捕获图上的不同邻域尺度。
    * 扩展了对比蒸馏目标以支持多个图结构，进一步合并上下文图的多关系信息。
* **实验数据集** ：
  * Gowalla
  * Yelp
  * Taobao2014

### 6. Structure Aware Incremental Learning with Personalized Imitation Weights for Recommender Systems

* **推荐任务** ：增量推荐
* **选自** ：AAAI2023
* **解决的问题** ：现有应对增量数据的方法倾向于为所有用户保留相同数量的历史信息，而这限制了模型的性能
* **思路和模型** ：
  * 思路：
    * 在大规模图上训练GNN成本高昂。应对新数据，完整重新训练难以接受，仅使用新数据则会导致灾难性遗忘。
    * 应对增量问题，知识蒸馏在效率和性能方面都具有优势，传统方法一般为所有用户保留相同数量的历史信息。
    * 不同用户的兴趣变化可能不一样，有些相对固定、少有增量信息，而有的经常改变，应个性化地设计。
    * 知识蒸馏目标函数中的超参数“模仿权重”对实现个性化的历史数据保留有重要作用。
  * 模型：带个性初始化权重的结构感知增量学习策略
    * 以到项目簇心的距离为度量，使用深度结构聚类方法对用户偏好分布进行聚类。
    * 为每个用户构建一个状态向量，向量对与该用户相关的偏好分布两两之间的距离进行编码。
    * 状态向量经过权重生成器，生成用户特定的模仿权重。
    * 模仿权重决定学生模型要从教师模型中继承多少与用户相关的历史信息。
* **实验数据集** ：
  * Gowalla
  * Yelp
  * Taobao 14
  * Taobao 15
  * Netflix

### 7. Boosting Meta-Learning Cold-Start Recommendation with Graph Neural Network

* **推荐任务** ：
* **选自** ：CIKM2023
* **解决的问题** ：现有基于元学习解决冷启动问题的方法大多假设源任务和目标任务之间存在相似数据分布，在新用户或交互极少的场景中效果不好。
* **思路和模型** ：
  * 思路：
    * 传统基于内容的和跨域方法可能会为不同的新用户推荐相同项目，忽略了个人兴趣。
    * 元学习有效的前提是源任务和目标任务具有相同或相似的分布，但新旧用户的兴趣可能差别很大，现有工作忽略了这一点。
  * 模型：使用GNN增强元学习冷启动推荐(boost Meta-learning cold-start recommendation with Graph Neural Network, MeGNN)
    * 全局邻域翻译学习：获得所有新用户和项目节点的一致潜在交互，从而细化表示。
    * 局部邻域翻译学习：预测每个结点的特定潜在交互，从而保证个性化需求。
    * 是一个即插即用组件，可与任何基于元学习的推荐模型结合。
* **实验数据集** ：
  * MovieLens 1M
  * DBook

### 8. Contrastive Meta Learning with Behavior Multiplicity for Recommendation

* **推荐任务** ：协同过滤
* **选自** ：WSDM2022
* **解决的问题** ：大多传统推荐模型无法根据多类型的用户行为数据对多重用户-项目名关系进行建模。
* **思路和模型** ：
  * 思路：
    * 实际推荐场景中，用户和项目之间存在多种类型的交互，不同类型的交互可以相互补充、从不同的维度表示用户偏好，而大多现有模型假设仅有一种类型。
    * 目标行为类型的交互通常很少，缺乏监督信号。
    * 多行为的模式可能因人而异，使用相同的用户-项目关系建模会导致次优的结果。
  * 模型：对比元学习(Contrastive Meta Learning)
    * 多行为对比学习框架：通过对比损失，从不同行为视图中捕获跨类型的交互依赖，从而提取到额外的监督信号。
    * 对比元网络：编码不同用户的定制行为异质性，捕获多样化的行为模式。
* **实验数据集** ：
  * Tmall
  * IJCAI-Contest
  * Retailrocket

### 9. Meta Graph Learning for Long-tail Recommendation

* **推荐任务** ：
* **选自** ：KDD2023
* **解决的问题** ：长尾项目分布会降低推荐系统中尾部项目的推荐效果。
* **思路和模型** ：
  * 思路：
    * 长尾问题在RS中长期存在，大量项目仅具有少量相关用户交互，从而产生流行度偏差。
    * 基于GNN的模型面对长尾问题时，多跳卷积会继续放大流行度偏差。
    * 部分尾部项目获得足够曝光后也能被用户广泛喜爱，尾项不等于坏项。
    * 元学习可以做到将从头部项目学到的知识迁移到尾部推荐中。
    * 在共享相同属性的头和尾部项目之间建立边可以增加推荐尾部的概率，但该方法忽略了原始二分结构的一致性。
    * 建立一个辅助图，用于学习项目之间的关系，而不是在原图的节点间添加边，可以解决上述问题。
    * 现有方法多将辅助图学习步骤直接与下游任务耦合，这并不适合长尾推荐，下游不平衡分布将进一步放大到学习到的图结构上。
    * 辅助图可能会将噪声引入头部项目表示中，从而导致负迁移。
  * 模型：针对长尾推荐的元图学习框架(Meta Graph Learning for Long-tail Recommendation, MGL)
    * 引入元学习方法，模拟辅助图训练过程中的学习和评估过程。
      * 学习阶段：训练元边缘生成器，从历史交互中重建有偏的项目共现矩阵并微调，从项目属性中提取项目协作关系。
      * 评估阶段：无偏元边生成器产生项目关系作为辅助图，从而适应下游任务且避免元边生成器过拟合于下游的带偏数据分布。
    * 流行度感知对比学习策略：将头部项目表示和学习到的辅助图表示进行对齐，防止负迁移。
* **实验数据集** ：
  * MovieLens-1M
  * Bookcrossing

## 三、对比分析

### 1. 有效处理增量信息

##### Causal Incremental Graph Convolution for Recommender System Retraining

- 思路：
  - 合并所有新旧数据，将模型完整重新训练效果很好，但成本非常高，且会随着时间不断增加。
  - 通过构建具有新交互的训练示例，对旧模型进行微调的成本相较完整训练更少，但由于还需要使用旧图更新参数，成本依然很高。
  - 仅利用新的交互来训练模型和图卷积。由于增量图较为稀疏，因此对计算资源的需求很小。但这样可能会切断旧图中的某些连接，容易产生过拟合和灾难性遗忘。
  - 高效的GCN推荐器再训练需要能够分离旧图、保留现有长期偏好、以及融合新旧偏好信号。
- 仅使用增量数据调整模型：利用增量图卷积算子融合新旧表示，并根据因果图中的碰撞效应，设计了碰撞效应蒸馏算子，通过控制碰撞器来估计新数据对不活动节点表示的因果影响，从而避免不在增量图中的非互动结点的过时问题。

##### Graph Structure Aware Contrastive Knowledge Distillation for Incremental Learning in Recommender Systems

- 思路：
  - 知识蒸馏/正则化是增量学习中常采用的方法，而现有利用知识蒸馏的工作也继承了知识蒸馏的缺点：由于学生网络结构通常更加简单，因此难以捕获高阶依赖关系。
  - 保留中间层的表示通常具有更宽泛的接受域(涵盖更多跳的邻居信息)，能更好地保留模型属性，但很少在现有工作中被使用。
- 结合对比学习和知识蒸馏，引入中间层蒸馏：结合对比蒸馏和中间层蒸馏，从而注入层级监督，使得学生网络学习到捕获高阶关系的能力。

##### CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning

- 思路：

  - 除了交互本身，交互的时间戳也能提供时间动态方面的信息。
  - 现有方法无法捕捉随时间变化的兴趣动态，忽略了最近的上下文对用户动态兴趣的影响。
- 构建多视图表示，将多个增量单目标堆叠为多目标任务联合优化：分别在静态嵌入、历史时间状态和上下文时间状态下位每个用户/项目创建三种表示；将增量单目标推荐堆叠到一个多目标任务中联合优化，提高时间状态演化和增量推荐的性能。

##### Contrastive Meta Learning with Behavior Multiplicity for Recommendation

- 思路：
  - 实际推荐场景中，用户和项目之间存在多种类型的交互，不同类型的交互可以相互补充、从不同的维度表示用户偏好，而大多现有模型假设仅有一种类型。
  - 目标行为类型的交互通常很少，缺乏监督信号。
  - 多行为的模式可能因人而异，使用相同的用户-项目关系建模会导致次优的结果。
- 结合对比学习与元学习：利用对比学习从不同行为视图中捕获跨类型的交互，提取额外的监督信号；利用对比元网络编码不同用户的定制行为异质性，提升模型适应新用户的能力。

##### Structure Aware Incremental Learning with Personalized Imitation Weights for Recommender Systems

- 思路：
  - 应对增量问题，知识蒸馏在效率和性能方面都具有优势，传统方法一般为所有用户保留相同数量的历史信息。
  - 不同用户的兴趣变化可能不一样，有些相对固定、少有增量信息，而有的经常改变，应个性化地设计。
  - 知识蒸馏目标函数中的超参数“模仿权重”对实现个性化的历史数据保留有重要作用。
- 个性化历史信息权重：利用状态向量经过权重生成器，生成用户特定的模仿权重，模仿权重决定学生模型要从教师模型中继承多少与用户相关的历史信息。

### 2. 冷启动

##### Deployable and Continuable Meta-learning-Based Recommender System with Fast User-Incremental Updates

- 思路：
  - 大多数基于元学习的RS通过支持集和查询集估计二阶导数，导致更新时的计算负担很重。
  - 要实现可部署的元学习RS，需要满足：
    - 1)避免灾难性遗忘
    - 2)稳定快速地进行用户增量更新
    - 3)有限的内存消耗
    - 4)易于实现、易于计算。
  - 广泛使用的增量RS方法有三种：完全再训练(FR)、基于样本的再训练(SR)和微调(FT)
  - FR违反了要求2、3，FT不满足要求1，SR是两者的折中，但也不能很好地整合两者的优点。
- 通过双约束任务采样器限制使用的内存：用最小化蒸馏损失和面向反馈的蒸馏损失同时约束任务采样，结合任务重传播和一阶梯度下降实现快速的用户增量更新。

##### Graph Few-shot Class-incremental Learning

- 思路：
  - 新出现的节点类别只有很少的标记样本可用，存在严重的类不平衡问题。
  - 这样的图少样本类增量学习(Graph Few-shot Class-incremental Learning, Graph FCL)问题较少受到关注。
  - 现有方法要么固定原模型特征编码器，难以学习增量任务；要么训练后在原有任务上表现不佳。
- 图伪增量学习范式：在基类上预训练编码器，并在后续增量学习中不冻结编码器；通过从基类和伪新类中循环采样任务，为模型产生任意数量的训练集练习增量学习技能。

##### Boosting Meta-Learning Cold-Start Recommendation with Graph Neural Network

- 思路：
  - 传统基于内容的和跨域方法可能会为不同的新用户推荐相同项目，忽略了个人兴趣。
  - 元学习有效的前提是源任务和目标任务具有相同或相似的分布，但新旧用户的兴趣可能差别很大，现有工作忽略了这一点。
- 结合GNN中的全局和局部邻域：使用全局邻域翻译学习获得所有新用户和项目节点的一致潜在交互，从而细化表示；使用局部邻域翻译学习预测每个结点的特定潜在交互，从而保证个性化需求。

### 3. 长尾问题

##### Meta Graph Learning for Long-tail Recommendation

- 思路：
  - 基于GNN的模型面对长尾问题时，多跳卷积会继续放大流行度偏差。
  - 在共享相同属性的头和尾部项目之间建立新的边可以增加推荐尾部的频次，但该方法破坏了原始二分结构的一致性。
  - 建立一个辅助图，用于学习项目之间的关系，而不是在原图的节点间添加边，可以解决上述问题。
  - 现有方法多将辅助图学习步骤直接与下游任务耦合，这并不适合长尾推荐，下游不平衡分布将进一步放大到学习到的图结构上。
- 利用元学习指导辅助图的训练：学习阶段：训练元边缘生成器，从历史交互中重建有偏的项目共现矩阵并微调，从项目属性中提取项目协作关系；评估阶段：使用无偏的元边生成器产生项目关系作为辅助图，从而适应下游任务且避免元边生成器过拟合于下游的带偏数据分布。
