# 第11周周报  覃海旭

本周工作主要是对跨域推荐方向相关的近期论文进行阅读与总结。

## 一、论文阅读

**1.Towards Open-world Cross-Domain Sequential Recommendation: A Model-Agnostic Contrastive Denoising Approach**

> 期刊会议：ECML PKDD2024
> 方向分类：跨域序列推荐/辅助行为引入

- **解决的问题：**

  1. 现有跨域序列推荐方法严重依赖于具有丰富行为的重叠用户，然而在实际场景中大多数用户都是交互较少的长尾用户和仅存在于单一域的冷启动用户，跨域信息的缺乏导致对该类用户的兴趣理解不完整。**该如何探索补充的兴趣信息以提升模型表现？**
  2. 最近的一些序列推荐研究已探索集成多种类型的行为以提升长尾用户的表现，然而这些方法未能考虑用户跨域兴趣的偏差以及目标行为和辅助行为之间的语义差距。**在利用辅助行为序列为长尾用户增强信息时，如何减少目标行为和辅助行为之间的语义差距并学习用户的兴趣偏差？**

- **创新点：**
  1. 首次在跨域序列推荐场景中引入辅助行为序列（如点击）来丰富用户的兴趣信息。
  2. 通过域内/跨域的多头注意力和对比学习方法来减少目标行为和辅助行为之间的语义差距。

<img src="C:\Users\qhx\AppData\Roaming\Typora\typora-user-images\image-20241111132356517.png" alt="image-20241111132356517" style="zoom: 40%;" />

- **模型架构：**MACD框架主要包括以下模块：
  - **域内去噪模块**：在单一域中利用多头注意力机制从辅助行为序列中提取显式兴趣。Q由目标项目交互序列得到，K,V由辅助行为序列得到。
  - **跨域去噪模块**：通过跨域多头注意力机制提取隐式兴趣，并实现跨域知识的迁移。Q由源域目标项目交互序列得到，K,V由辅助域的辅助行为序列得到。
  - **对比信息正则化器**：同一用户在在域内去噪模块和跨域去噪模块得到的表示为正样本，不同用户在上面两个模块得到的表示为负样本。使得模型能够学习到更具一致性的用户兴趣感知表示，同时能够区分不同用户的个性化偏好。
  - **融合门控单元**：通过可学习的权重矩阵实现用户显式兴趣表示和隐式兴趣表示的加权融合，得到用户在每个领域中的整体偏好表示。
  - **归纳表示生成器**：为冷启动用户生成归纳表示，通过在另一域中检索与其兴趣相似的用户的嵌入向量来替代冷启动用户的嵌入，从而有效提升冷启动用户的推荐效果。
- **数据集：**在下面2个跨域场景下进行实验：
  1. Amazon(Cloth/Sport)
  2. Amazon(Phone/Elec)

**2.Towards Open-world Cross-Domain Sequential Recommendation: A Model-Agnostic Contrastive Denoising Approach**

> 期刊会议：EDBT2025
> 方向分类：跨域推荐/基于评论的推荐

- **解决的问题：**

  跨域推荐场景下的数据稀疏和冷启动（非重叠用户）问题。

  跨域推荐的核心任务是两个相关领域之间的用户偏好映射。现有方法从两个领域的重叠用户中学习跨域映射，从而实现跨域知识转移。然而在数据匮乏的情况下，这些方法难以获得稳健的用户和物品表示，导致在跨域映射函数过程中出现误差传播问题。

- **创新点：**

  与传统通过映射函数将源域用户特征转化为目标域特征的方法不同，OmniMatch 通过为冷启动用户生成辅助评论，以便挖掘和传递领域无关的信息。

  基于下面2种假设：(1)用户在各个域中具有相似的偏好。(2)如果用户对同一物品给出了相同的评分，则他们可能在一定程度上有相似的偏好。OmniMatch首先在源域中找到所有对某物品给予相同评分的重叠用户（称为志趣相投用户）。然后，通过从志趣相投用户中随机选择一个目标域的评论，将其作为该冷启动用户的辅助评论。

<img src="C:\Users\qhx\AppData\Roaming\Typora\typora-user-images\image-20241111132715306.png" alt="image-20241111132715306" style="zoom:55%;" />

- **模型架构：**OmniMatch由以下几个模块构成：
  - **辅助评论生成模块**：针对冷启动用户在目标领域没有评论的情况，通过源域中相似用户的评论为其生成目标领域的辅助评论。
  - **特征提取模块**：该模块使用卷积层和MLP提取用户在源域和目标域的领域共享和领域特定特征，以及每个域的物品特征。
  - **对比表示学习模块**：使用监督对比损失来保证同一用户在源域和目标域的特征在潜在空间中更为接近，同时拉近具有相同评分的用户-物品对之间的距离。
  - **领域对抗训练模块**：通过域分类器和梯度反转层使用户特征保持领域无关，减少源域和目标域特征分布的差异。
- **数据集：**
  - Amazon(Books/Music/Movies)
  - Douban(Books/Music/Movies)

**3.AutoTransfer: Instance Transfer for Cross-Domain Recommendations**

> 期刊会议：SIGIR2023
> 方向分类：跨域推荐/实例迁移

- **解决的问题：**

  大多数现有的跨域推荐方法关注于从源领域提取隐式信息以增强目标领域。然而，提取出的隐式信息的隐藏结构高度依赖于特定模型，因此不易复用或迁移。此外，提取的隐式信息仅出现在模型的中间子结构中，并且仅在训练过程中存在，因此难以保留以供后续使用。

- **创新点：**

  **显式实例迁移**：首次提出了一种直接从源领域选择并迁移数据实例到目标领域的显式迁移框架，避免了对隐式特征的依赖。

<img src="C:\Users\qhx\AppData\Roaming\Typora\typora-user-images\image-20241111133120648.png" alt="image-20241111133120648" style="zoom:35%;" />

- **模型架构：**AutoTransfer由两个训练阶段训练的两大核心组件组成：

  - **搜索阶段**

    通过<u>强化学习</u>训练一个用于实例选择的<u>控制器网络</u>，用于从源领域中选择对目标领域训练有帮助的实例。

    - 控制器网络对源领域实例逐一评估，通过策略选择“有用”或“无用”实例，优化实例选择策略。
    - 使用目标领域验证集的评估结果和损失函数变化为控制器生成奖励信号。

  - **目标训练阶段**

    利用筛选后的源领域实例和目标领域实例训练一个<u>骨干推荐系统模型</u>（任意的单域推荐模型），用于在目标领域进行推荐任务并生成用于优化控制器网络的奖励信号。

- **数据集：**在下面3个跨域场景下进行实验：

  - MovieLens-25m(Horror/Noir)
  - Amazon(Automotive/Industrial and Scientific)
  - Amazon(Toys and Games/Industrial and Scientific)

**4.M2GNN: Metapath and Multi-interest Aggregated Graph Neural Network for Tag-based Cross-domain Recommendation**

> 期刊会议：SIGIR2023
> 方向分类：基于标签的跨域推荐

- **解决的问题：**
  1. 长文本描述在实际场景中比较稀缺，更常见的是轻量级的文本特征（如少量关键词或标签），但现有方法对此的建模能力不足。
  2. 在跨域推荐中，不是所有跨域兴趣对目标域都有帮助，因此需要有效地提取对目标域有用的兴趣信息，同时过滤掉噪声（负迁移问题）。
- **创新点：**

  - 利用图神经网络建模高阶连接关系的能力，建立了一个与标签相关的异构图来建模多源行为，其中每个领域通过元路径表示。
  - 提出了一种分层聚合模式来学习当嘈杂的邻居节点占多数时的用户偏好。
    - 第一步使用动态路由网络过滤无关标签，并提取多层次用户兴趣。
    - 第二步利用自注意力机制进一步将重要的兴趣信息转移到目标域。
  - 引入Skip-gram正则化，增强标签嵌入的语义相关性。

<img src="C:\Users\qhx\AppData\Roaming\Typora\typora-user-images\image-20241111133422714.png" alt="image-20241111133422714" style="zoom:67%;" />

- **模型架构：**M2GNN由以下几个模块组成：
  - **输入建模**：通过构建异构图将用户、项目和标签在跨域上下文中关联，每个域通过不同的元路径建模用户行为。
  - **两步聚合**：
    - **域内聚合**：使用动态路由网络，通过权重更新机制过滤无关标签并动态计算用户的多个兴趣向量，每个兴趣表示用户在一个领域的不同偏好。
    - **跨域聚合**：通过自注意力机制，将将来自不同领域的兴趣向量加权合并到目标域，优先保留对目标域有用的信息。使用指数加权方法进一步增强重要兴趣向量的权重。
  - **Skip-gram正则化**：通过优化标签嵌入，增强标签语义相关性并去除无关标签，减少噪声对模型的影响。具体而言，将标签节点视为中心词，其同质邻居节点视为附近词语。核心原则是最大化相关标签的共现概率，同时最小化不相关标签的共现概率。
- **数据集：**
  - DPBJ（未公开）
  - Amazon(Book/Movie)

## 二、对比总结

对已阅读的跨域推荐相关论文进行对比总结：

**对抗训练（GAN）思想的应用：**

|          模型          |                             方法                             |                             目的                             |
| :--------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| DiCUR-CDR(第9周第1篇)  | 生成器生成反馈向量，判别器判别该反馈向量是生成器生成的还是用户真实的反馈 |         使得生成器生成更加真实的反馈向量作为推荐结果         |
|    CDAT(第9周第2篇)    | 生成器编码源域和目标域的领域不变的用户偏好分布（可以理解为域共享表示）,判别器判别该表示来自源域还是目标域 |          使得生成器编码的用户偏好表示具有领域不变性          |
| $C^{2}DR$(第10周第4篇) | 生成器编码域特定表示和域共享表示，域分类器用作判别器，判别输入的表示是域共享表示还是域特定表示。引入梯度反转层用于欺骗分类器，使得模型更难以区分域共享信息和域特定信息 | 使得生成器编码的共享表示真正对所有域都通用，而特定表示仅适用于相应的域 |
| OmniMatch(第11周第2篇) | 与$C^{2}DR$的方式基本相同，同样是采用具有梯度反转层的域分类器进行对抗训练 |    使用户特征保持领域无关，减少源域和目标域特征分布的差异    |

**域共享表示和域特定表示的解耦：**

|          模型          |       方法       |                             目的                             |
| :--------------------: | :--------------: | :----------------------------------------------------------: |
| DiCUR-CDR(第9周第1篇)  | 判别典型相关分析 | 在最大化域共享用户表示之间的相关性的同时添加额外的约束来学习域特定表示之间的差异 |
|  MITrans(第10周第2篇)  |    互信息约束    | 最大化不同域间物品嵌入的相似度以学习共享偏好，最小化域间物品嵌入的依赖关系以保留特定偏好 |
| $C^{2}DR$(第10周第4篇) |   因果表示解耦   | 确保域共享表示和域特定表示的向量正交性（余弦相似度最小化）和统计分布独立性（协方差为0） |

**负迁移问题的优化：**

|          模型          |                 方法                  |                             目的                             |
| :--------------------: | :-----------------------------------: | :----------------------------------------------------------: |
|    PPA(第9周第5篇)     |             原型感知学习              |  通过构建偏好原型以量化用户偏好，从而减少源域冗余特征的影响  |
|    CUT(第10周第1篇)    |              相似性约束               | 通过限制损失函数让目标域中相似的用户对的嵌入在源域中仍然保持相似 |
| CrossAug(第10周第3篇)  |             特征交叉重构              |                通过数据增强的方式来缓解负迁移                |
| $C^{2}DR$(第10周第4篇) |              正交化约束               | 强制域共享信息在两个域的损失函数梯度之间保持正交性。确保域特定信息在一个域内仅影响该域的推荐结果，不会对其他域的推荐产生干扰 |
|   M2GNN(第11周第4篇)   | 动态路由网络+自注意力+skip-gram正则化 |    增强标签语义相关性并去除无关标签，减少噪声对模型的影响    |

**无重叠user/item下的跨域推荐：**

|         模型         |                  方法                  |
| :------------------: | :------------------------------------: |
| PrepRec(第9周第4篇)  | 通过建模物品流行度的变化来学习通用表示 |
| MITrans(第10周第2篇) |    通过互信息来学习不同域的共享偏好    |

**特征信息补充/增强样本的生成:**

|           模型            |                             方法                             |
| :-----------------------: | :----------------------------------------------------------: |
|     MACD(第11周第1篇)     |        引入辅助行为序列（如点击）来丰富用户的兴趣信息        |
|  OmniMatch(第11周第2篇)   |     用辅助域相似用户的评论作为目标域冷启动用户的辅助评论     |
|    M2GNN(第11周第4篇)     |                         引入标签信息                         |
| AutoTransfer(第11周第3篇) |               显式选择源域中的实例迁移到目标域               |
|   CrossAug(第10周第3篇)   |         通过特征交叉重构的方式生成域内和跨域增强样本         |
|   MITrans(第10周第2篇)    | 通过预训练语言模型(BERT)，从项目文本数据中提取语义嵌入，用于后续的偏好学习 |

