# 第10周周报 覃海旭

本周工作主要是对跨域推荐方向相关的近期论文进行阅读与总结。

## 一、论文阅读

**1、Aiming at the Target: Filter Collaborative Information for Cross-Domain Recommendation**

> 期刊会议：SIGIR2024
> 方向分类：跨域推荐/负迁移问题

- **解决的问题：**

  跨域推荐中的负迁移问题，即源域中的无关信息可能对目标域的推荐性能产生负面影响。

  现有方法大多依赖对重叠用户的自适应表示进行调整，而缺乏对源域无关协同信息的显式过滤，因而无法有效避免负迁移。

- **创新点：**

  通过目标域用户相似性约束来指导用户信息的过滤，以限制源域无关信息的干扰，直接针对负迁移问题进行优化。

  简单来说，就是通过限制损失函数让目标域中相似的用户对的嵌入在源域中仍然保持相似。


<img src="C:\Users\qhx\AppData\Roaming\Typora\typora-user-images\image-20241104112006687.png" alt="image-20241104112006687" style="zoom:67%;" />

- **模型架构：**CUT框架分为两个阶段：

  1. **TARGET阶段：**在目标域内训练一个单域推荐模型，以学习目标域用户的相似性关系。此阶段生成的用户相似性矩阵作为指导信号，用于后续的信息过滤。
  2. **TRANSFER阶段：**在源域和目标域的组合数据上进一步训练模型。其核心在于用户转换层和对比损失的使用。
     - 用户转换层帮助重叠用户在不同域之间进行自适应的表征转换。
     - 对比损失则用于保持目标域用户相似性。

- **数据集：**在下面三个跨域场景下进行实验：

  1. Amazon(Sports/Cloth)
  2. Amazon(Video/Cloth)
  3. Douban(Music/Movie)

**2、Mutual Information-based Preference Disentangling and Transferring for Non-overlapped Multi-target Cross-domain Recommendations**

> 期刊会议：SIGIR2024
> 方向分类：非重叠多目标跨域推荐(非重叠：指不同推荐域之间没有共享用户或项目，多目标：域的数量>2)

- **解决的问题：**

  现有的跨域推荐方法大多仅适用于两个域之间的推荐，且通常依赖于域共享用户或项目来传递知识。而在实际应用中，不同域之间的用户或项目往往无法共享。因此本论文聚焦于一个更通用的场景，即非重叠多目标跨域推荐。

- **创新点：**

  - **互信息约束解耦**：提出了两个新的互信息约束，即AFCLUB和AFDCE，用于在无共享用户或项目的前提下解耦域共享和域特定偏好。AFDCE最大化不同域间物品嵌入的相似度以学习共享偏好，AFCLUB最小化域间物品嵌入的依赖关系以保留特定偏好。
- **多域图传递：**对各域项目进行聚类，构建跨域聚类图，融合共享偏好，再在每域内构建聚类-项目图，将跨域共享偏好传递至项目嵌入，利用图卷积网络提升各域推荐效果。
  - **偏好融合：**通过域共享的项目嵌入和域特定的项目嵌入分别计算用户的两种偏好评分，然后利用KL散度最小化这两种评分之间的差异，从而将共享偏好和特定偏好融合到域特定的项目嵌入中。


<img src="C:\Users\qhx\AppData\Roaming\Typora\typora-user-images\image-20241104111802710.png" alt="image-20241104111802710" style="zoom: 67%;" />

- **模型架构：**MITrans包含三个主要模块：
  - **语义嵌入模块**：通过预训练语言模型(BERT)，从项目文本数据中提取语义嵌入，用于后续的偏好学习。
  - **偏好解耦学习模块**：构建了域共享和域特定嵌入，利用AFCLUB和AFDCE约束分别提取域共享和域特定的偏好。通过这些约束，MITrans能够有效分离和学习两类偏好。
  - **偏好融合模块**：通过多域图传输和聚合的方式融合不同域的共享偏好。首先利用多层图卷积网络将共享偏好聚合为增强嵌入，之后将其与每个域的特定偏好进行融合，进一步提升推荐效果。
  
- **数据集：**

  1. Amazon(Books/Movies/Sports/Games)
  2. Douban(Books/Movies/Musics)

**3、Cross-reconstructed Augmentation for Dual-target Cross-domain Recommendation**

> 期刊会议：SIGIR2024
> 方向分类：跨域推荐/数据增强

- **解决的问题：**

  近年提出的双目标跨域推荐通过双向信息转移，致力于在两个域之间实现相互增强。然而，当前的双目标跨域推荐方法主要集中在设计强大的编码器以学习跨域信息，而未能解决根本的数据交互不足问题。此外，在不同领域间转移信息时，由于数据分布差异，易引入负迁移的风险。

- **创新点：**

  1. **假设：**如果给用户展示一个包含他喜欢和不喜欢的特征的物品，那么该物品的评分会低于他最喜欢的物品，但高于他最不喜欢的物品。

       基于上述假设，论文提出域内增强和跨域增强两种数据增强方法：

     - **域内增强：**在同一域内构造由正样本和负样本特征交叉重构的中间样本，然后基于假设对评分模型进行排序关系建模。
     - **跨域增强：**与域内增强相似，利用重叠用户来自不同域的正样本和负样本进行重构生成中间样本，再对评分模型进行排序关系建模。


  2. 引入**Householder变换**，将两个域的共享表示投射到一个联合空间中，并应用中心对齐来减少域偏移带来的负面影响。

<img src="C:\Users\qhx\AppData\Roaming\Typora\typora-user-images\image-20241104111916551.png" alt="image-20241104111916551" style="zoom: 80%;" />

- **模型架构：**CrossAug分为以下几个模块：
  - **跨域图传播模块**：该模块作为基础编码器，将用户-物品交互构造成双域的二分图。利用重叠用户节点来进行跨域图传播，模型聚合邻域信息并提取跨域共享的知识。
  - **域内增强模块**：通过同一域中正负样本对的组合，构建跨重构的中间样本，以充分利用数据而无需额外的负采样。
  - **跨域增强模块**：与域内增强相似，在双域的正负样本对之间生成中间表示，用于捕捉跨域的用户偏好。
  - **中心对齐模块**：通过Householder变换将共享表示投射到联合空间，并对齐两个域的中心，减少域偏移的负迁移影响。
- **数据集：**在下面两个跨域场景下进行实验：
  1. Amazon(Movie/Music)
  2. Amazon(Cell/Elec)

**4、$C^{2}DR$: Robust Cross-Domain Recommendation based on Causal Disentanglement**

> 期刊会议：WSDM2024
> 方向分类：跨域推荐/负迁移问题

- **解决的问题：**

  现有的跨域推荐方法往往忽视了用用户在物品上的域特定偏好建模，从源域纳入域特定偏好会引入无关信息，从而导致目标域的性能下降。

- **创新点：**

  1. 从因果推断的角度出发，将域共享信息和域特定信息视作因果变量，并设计了因果解耦正则化项，来确保域共享和域特定信息在表示空间中满足因果独立性（即向量正交性和统计分布独立性），从而防止域特定信息不恰当地被转移。
  2. 采用GAN的思想，设计带有梯度反转层的域分类器。分类器用于判别域共享信息与域特定信息，而梯度反转层用于欺骗分类器，使得模型更难以区分域共享信息和域特定信息。这样来迫使编码器编码的共享信息和特定信息的独特性更为明显。

<img src="C:\Users\qhx\AppData\Roaming\Typora\typora-user-images\image-20241104111641243.png" alt="image-20241104111641243" style="zoom: 67%;" />

- **模型架构：**$C^{2}DR$的模型架构包括以下几个模块：
  - **因果表示学习**：模型通过多个编码器来分别学习用户在每个域的特定偏好和共享偏好。域共享信息被认为是不受特定域影响的高层次偏好，而域特定信息则是只在该域中有意义的精细偏好。
  - **因果表示解耦**：为了分离不同域的信息，$C^{2}DR$引入了一个域分类器，并在该分类器上使用梯度反转层（GRL）来提取域共享信息。通过最大化域分类准确率，模型能够更好地将共享信息和特定信息解耦。
  - **因果嵌入的独立性处理:**为了确保域共享信息和域特定信息相互独立，模型从空间几何和统计分布两个角度对因果嵌入进行独立性处理。
    - <u>空间几何角度：</u>通过一个向量正交正则项使域共享信息与域特定信息之间的余弦相似度最小化，从而在表示空间中保持这些嵌入的正交性，确保其独立性。
    - <u>统计分布角度：</u>引入了一个可学习的权重向量，通过重新加权域共享和域特定信息，来使不同嵌入之间的协方差为零。
  - **域无关信息控制:**引入了一个正交化约束，强制域共享信息在两个域的损失函数梯度之间保持正交性。这一正交化约束确保域特定信息在一个域内仅影响该域的推荐结果，不会对其他域的推荐产生干扰，从而避免负迁移。
  - **正交化约束**：模型还添加了正交化约束，确保域共享信息的梯度在各域损失函数间正交。这种设计保证了域共享信息和域特定信息在迁移时互不干扰，从而实现了有效的因果变量干预和转移。
  
- **数据集：**在下面三个跨域场景下进行实验：

  - Huawei(news/advertisement)
  - Amazon(movie/music)
  - Douban(Movie/Book)

## 二、对比总结

与上周的5篇论文一起（共9篇）进行对比总结：

**对抗训练（GAN）思想的应用：**

|          模型          |                             方法                             |                             目的                             |
| :--------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| DiCUR-CDR(第9周第1篇)  | 生成器生成反馈向量，判别器判别该反馈向量是生成器生成的还是用户真实的反馈 |         使得生成器生成更加真实的反馈向量作为推荐结果         |
|    CDAT(第9周第2篇)    | 生成器编码源域和目标域的领域不变的用户偏好分布（可以理解为域共享表示）,判别器判别该表示来自源域还是目标域 |          使得生成器编码的用户偏好表示具有领域不变性          |
| $C^{2}DR$(第10周第4篇) | 生成器编码域特定表示和域共享表示，域分类器用作判别器，判别输入的表示是域共享表示还是域特定表示 | 使得生成器编码的共享表示真正对所有域都通用，而特定表示仅适用于相应的域 |

**域共享表示和域特定表示的解耦：**

|          模型          |       方法       |                             目的                             |
| :--------------------: | :--------------: | :----------------------------------------------------------: |
| DiCUR-CDR(第9周第1篇)  | 判别典型相关分析 | 在最大化域共享用户表示之间的相关性的同时添加额外的约束来学习域特定表示之间的差异 |
|  MITrans(第10周第2篇)  |    互信息约束    | 最大化不同域间物品嵌入的相似度以学习共享偏好，最小化域间物品嵌入的依赖关系以保留特定偏好 |
| $C^{2}DR$(第10周第4篇) |   因果表示解耦   | 确保域共享表示和域特定表示的向量正交性（余弦相似度最小化）和统计分布独立性（协方差为0） |

**负迁移问题的优化：**

|          模型          |     方法     |                             目的                             |
| :--------------------: | :----------: | :----------------------------------------------------------: |
|    PPA(第9周第5篇)     | 原型感知学习 |  通过构建偏好原型以量化用户偏好，从而减少源域冗余特征的影响  |
|    CUT(第10周第1篇)    |  相似性约束  | 通过限制损失函数让目标域中相似的用户对的嵌入在源域中仍然保持相似 |
| CrossAug(第10周第3篇)  | 特征交叉重构 |                通过数据增强的方式来缓解负迁移                |
| $C^{2}DR$(第10周第4篇) |  正交化约束  | 强制域共享信息在两个域的损失函数梯度之间保持正交性。确保域特定信息在一个域内仅影响该域的推荐结果，不会对其他域的推荐产生干扰 |

**无重叠user/item下的跨域推荐：**

|         模型         |                  方法                  |
| :------------------: | :------------------------------------: |
| PrepRec(第9周第4篇)  | 通过建模物品流行度的变化来学习通用表示 |
| MITrans(第10周第2篇) |    通过互信息来学习不同域的共享偏好    |

